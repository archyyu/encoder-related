{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQm3CqAU7x08cZHmQV1fN+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archyyu/encoder-related/blob/main/encoder_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nFaVGmvM2FOC"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/archyyu/publicResource/main/chat_dataset.csv')"
      ],
      "metadata": {
        "id": "9fz7e2OpQvQt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "hidden_size = 100\n",
        "embedding_dim = 40\n",
        "seq_length = 25\n",
        "learning_rate = 1e-1\n",
        "batch_size = 20\n",
        "dropout = 0.1\n",
        "eval_iters = 200\n",
        "num_heads = 8\n",
        "head_size = 16"
      ],
      "metadata": {
        "id": "7_VDGwea6Ktm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad = '[pad]'\n",
        "mask = '[MASK]'\n",
        "data = []\n",
        "targets = []\n",
        "for index, row in df.iterrows():\n",
        "  data.append(row['message'])\n",
        "  targets.append(row['sentiment'])"
      ],
      "metadata": {
        "id": "4INzfntYQ5IE"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datalen = []\n",
        "for line in data:\n",
        "  datalen.append(len(line.split(' ')))"
      ],
      "metadata": {
        "id": "fdwC_j_G32R8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targetset = sorted(set(targets))\n",
        "sentiment_to_index = {s:i for i, s in enumerate(targetset)}\n",
        "index_to_sentiment = {i:s for i, s in enumerate(targetset)}"
      ],
      "metadata": {
        "id": "_AZ900ZBSPyU"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sorted(set((' '.join(data)).split(' ')))\n",
        "dataset.append(pad)\n",
        "dataset.append(mask)\n",
        "vocab_size = len(dataset)\n",
        "word_to_index = {w:i for i, w in enumerate(dataset)}\n",
        "index_to_word = {i:w for i, w in enumerate(dataset)}"
      ],
      "metadata": {
        "id": "fYvtMMv0SXvp"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbhbiYR35mLT",
        "outputId": "af34ed34-c492-4fec-c653-706ce177b263"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "902"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = []\n",
        "for item in data:\n",
        "  lines.append(item.split(' '))\n",
        "\n",
        "max_line = max([len(line) for line in lines])"
      ],
      "metadata": {
        "id": "5AVifPEUX7Mr"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in lines:\n",
        "  for _ in range(max_line - len(item)):\n",
        "    item.append(pad)"
      ],
      "metadata": {
        "id": "nvcrv9J3Yfpt"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "for line in lines:\n",
        "  item = [word_to_index[word] for word in line]\n",
        "  X.append(item)\n",
        "\n",
        "Y = []\n",
        "for i in range(len(targets)):\n",
        "  item = sentiment_to_index[targets[i]]\n",
        "  Y.append(item)"
      ],
      "metadata": {
        "id": "bYBoiEbOTy83"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self, embedding_size, head_size):\n",
        "    super(AttentionHead, self).__init__()\n",
        "    self.head_size = head_size\n",
        "    self.C = embedding_size\n",
        "\n",
        "    self.q = nn.Linear(self.C, head_size, bias=False)\n",
        "    self.v = nn.Linear(self.C, head_size, bias=False)\n",
        "    self.k = nn.Linear(self.C, head_size, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B,T,C = x.shape\n",
        "    q = self.q(x)\n",
        "    k = self.k(x)\n",
        "    v = self.v(x)\n",
        "\n",
        "    wei = q @ k.transpose(-2, -1) * (self.head_size ** -0.5)\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "    return wei @ v\n",
        "\n",
        "class EncoderMultiHeadAttention(nn.Module):\n",
        "  def __init__(self, num_heads, embedding_size, head_size):\n",
        "    super(EncoderMultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.heads = nn.ModuleList([\n",
        "        AttentionHead(embedding_size, head_size) for _ in range(num_heads)\n",
        "    ])\n",
        "\n",
        "    self.final_linear = nn.Linear(num_heads * head_size, embedding_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    head_outputs = [head(x) for head in self.heads]\n",
        "    concatenated_output = torch.cat(head_outputs, dim=-1)\n",
        "    final_output = self.final_linear(concatenated_output)\n",
        "    return self.dropout(final_output)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, embedding_size):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(embedding_size, 4 * embedding_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4 * embedding_size, embedding_size),\n",
        "        nn.Dropout(dropout),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "class EncoderBlockAttention(nn.Module):\n",
        "  def __init__(self, num_heads, embedding_size, head_size):\n",
        "    super(EncoderBlockAttention, self).__init__()\n",
        "    self.multiheads = EncoderMultiHeadAttention(num_heads, embedding_size, head_size)\n",
        "    self.fw = FeedForward(embedding_size)\n",
        "    self.norm1 = nn.LayerNorm(embedding_size)\n",
        "    self.norm2 = nn.LayerNorm(embedding_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    inter_result = x + self.multiheads(self.norm1(x))\n",
        "    final_result = x + self.fw(self.norm2(inter_result))\n",
        "    return final_result\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, num_heads, vocab_size, embedding_size, head_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.em = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.pos_encode = nn.Embedding(seq_length, embedding_size)\n",
        "    self.blocks = nn.ModuleList([EncoderBlockAttention(num_heads, embedding_size, head_size) for _ in range(4)])\n",
        "    self.f_norm = nn.LayerNorm(embedding_size)\n",
        "    self.fw = nn.Linear(embedding_size, vocab_size, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B,T = x.shape\n",
        "    x_em = self.em(x)\n",
        "    p_em = self.pos_encode(torch.arange(T))\n",
        "\n",
        "    x = x_em + p_em\n",
        "    for block in self.blocks:\n",
        "      x = block(x)\n",
        "    x = self.f_norm(x)\n",
        "    x = self.fw(x)\n",
        "    return x\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = Encoder(num_heads, vocab_size, embedding_dim, head_size)\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "SIGRVqLNVdgF"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch():\n",
        "  inputs = []\n",
        "  targets = []\n",
        "  mask_index_list = []\n",
        "  n = torch.randint(len(X) - batch_size, [1]).item()\n",
        "  for i in range(batch_size):\n",
        "    inputs_item = torch.tensor(X[n + i])\n",
        "\n",
        "    mask_index = torch.randint(datalen[n + 1], [1])\n",
        "\n",
        "    targets.append(inputs_item[mask_index])\n",
        "    mask_index_list.append(torch.tensor([i,mask_index]))\n",
        "\n",
        "    inputs_item[mask_index] = word_to_index[mask]\n",
        "\n",
        "    inputs.append(inputs_item)\n",
        "\n",
        "  return torch.stack(inputs), torch.stack(targets), torch.stack(mask_index_list)"
      ],
      "metadata": {
        "id": "h5OFKwKM6ElH"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets, mask_indices = get_batch()\n",
        "print(inputs)\n",
        "print(targets)\n",
        "print(inputs[mask_indices[:,0],mask_indices[:,1]])"
      ],
      "metadata": {
        "id": "0fOtjaFr-AAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iters = 5000\n",
        "for i in range(n_iters):\n",
        "  inputs, targets, indices = get_batch()\n",
        "\n",
        "  predicts = model(inputs)\n",
        "\n",
        "  #print(targets.view(-1).shape)\n",
        "  outputs = predicts[indices[:,0],indices[:,1]]\n",
        "  #print(outputs.shape)\n",
        "\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "  loss = criterion(outputs, targets.view(-1))\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  if i%500 == 0:\n",
        "    print(f'i {i}, loss:{loss.item()}')"
      ],
      "metadata": {
        "id": "jamQ4eJv7Vdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067c1511-ec52-4e51-bef4-75d46ed8240b"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i 0, loss:0.857141375541687\n",
            "i 500, loss:0.6623756885528564\n",
            "i 1000, loss:2.761378526687622\n",
            "i 1500, loss:3.16829776763916\n",
            "i 2000, loss:1.24629807472229\n",
            "i 2500, loss:0.34113749861717224\n",
            "i 3000, loss:1.2097088098526\n",
            "i 3500, loss:2.2975268363952637\n",
            "i 4000, loss:2.341250419616699\n",
            "i 4500, loss:2.9368631839752197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hhh = \"I have no opinion [MASK] this\"\n",
        "\n",
        "hgg = [word_to_index[word] for word in hhh.split(' ')]\n",
        "for i in range(max_line - len(hgg)):\n",
        "  hgg.append(word_to_index[pad])\n",
        "\n",
        "# hgg = torch.stack(hgg)\n",
        "\n",
        "hgg = torch.tensor(hgg).unsqueeze(0)\n",
        "\n",
        "predict = model(hgg)"
      ],
      "metadata": {
        "id": "VBo-hU1c7ZnD"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values, indexes = torch.topk(predict[0][4],2)\n",
        "for item in indexes:\n",
        "  print(index_to_word[item.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji4vN_sRKYj_",
        "outputId": "473488ab-458f-418f-b918-77b38f047c34"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "on\n",
            "about\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "that is amazing\n",
        "I masked one word in the sentence, then training to model to predict the masked word\n",
        "\n",
        "after some epoches, it works.\n",
        "\n",
        "will continue"
      ],
      "metadata": {
        "id": "y_9ByyHrMDU2"
      }
    }
  ]
}