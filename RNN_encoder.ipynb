{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUP3Tzr1t97z+hXoS2kYG5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archyyu/encoder-related/blob/main/RNN_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xYsdkDbbc390"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/archyyu/publicResource/main/chat_dataset.csv')"
      ],
      "metadata": {
        "id": "28qXGa_hdo-b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "hidden_size = 100\n",
        "embedding_dim = 100\n",
        "seq_length = 25\n",
        "learning_rate = 1e-2\n",
        "batch_size = 20\n",
        "dropout = 0.1\n",
        "eval_iters = 200\n",
        "head_size = 20"
      ],
      "metadata": {
        "id": "0j7w6ZHKdsCf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad = ''\n",
        "data = []\n",
        "targets = []\n",
        "for index, row in df.iterrows():\n",
        "  data.append(row['message'])\n",
        "  targets.append(row['sentiment'])\n",
        "\n",
        "targetset = sorted(set(targets))\n",
        "sentiment_to_index = {s:i for i, s in enumerate(targetset)}\n",
        "index_to_sentiment = {i:s for i, s in enumerate(targetset)}\n",
        "\n",
        "dataset = sorted(set((' '.join(data)).split(' ')))\n",
        "dataset.append(pad)\n",
        "vocab_size = len(dataset)\n",
        "word_to_index = {w:i for i, w in enumerate(dataset)}\n",
        "index_to_word = {i:w for i, w in enumerate(dataset)}\n",
        "\n",
        "lines = []\n",
        "for item in data:\n",
        "  lines.append(item.split(' '))\n",
        "\n",
        "max_line = max([len(line) for line in lines])\n",
        "\n",
        "for item in lines:\n",
        "  for _ in range(max_line - len(item)):\n",
        "    item.append(pad)\n",
        "\n",
        "X = []\n",
        "for line in lines:\n",
        "  item = [word_to_index[word] for word in line]\n",
        "  X.append(item)\n",
        "\n",
        "Y = []\n",
        "for i in range(len(targets)):\n",
        "  item = sentiment_to_index[targets[i]]\n",
        "  Y.append(item)"
      ],
      "metadata": {
        "id": "gr47YlO4dudg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch():\n",
        "  inputs = []\n",
        "  targets = []\n",
        "\n",
        "  pad_index = word_to_index[pad]\n",
        "\n",
        "  n = torch.randint(len(X) - batch_size, [1]).item()\n",
        "  for i in range(batch_size):\n",
        "\n",
        "    inputs_item = torch.tensor(X[n + i])\n",
        "    targets_item = torch.tensor(Y[n + i])\n",
        "    inputs.append(inputs_item)\n",
        "    targets.append(targets_item)\n",
        "\n",
        "  return torch.stack(inputs), torch.stack(targets)"
      ],
      "metadata": {
        "id": "-xHTyKyXdyzE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Attention, self).__init__()\n",
        "    self.attn = nn.Linear(hidden_size, hidden_size)\n",
        "    self.v = nn.Parameter(torch.rand(hidden_size))\n",
        "\n",
        "  def forward(self, encoder_outputs):\n",
        "    seq_len = encoder_outputs.size(1)\n",
        "    energy = torch.tanh(self.attn(encoder_outputs))\n",
        "    attention_scores = torch.matmul(energy, self.v)\n",
        "    attention_weights = torch.softmax(attention_scores, dim=1)\n",
        "    context_vector = torch.sum(attention_weights.unsqueeze(2) * encoder_outputs, dim=1)\n",
        "    return context_vector\n",
        "\n",
        "class ManillaRNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
        "    super(ManillaRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.i2h = nn.Linear(embedding_dim, hidden_size)\n",
        "    self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "    self.h2o = nn.Linear(hidden_size, output_size)\n",
        "    self.hb2 = nn.Parameter(torch.zeros(1, hidden_size))\n",
        "    self.ob = nn.Parameter(torch.zeros(1, output_size))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.o2o = nn.Linear(hidden_size, output_size)\n",
        "    self.att = Attention(hidden_size)\n",
        "\n",
        "  def forward(self, x, targets):\n",
        "    h = torch.zeros(1, self.hidden_size)\n",
        "    h_list = []\n",
        "    for i in range(x.shape[1]):\n",
        "      t = self.embedding(x[:,i])\n",
        "      h = torch.tanh(self.i2h(t) + self.h2h(h) + self.hb2)\n",
        "      y = self.dropout(self.h2o(h) + self.ob)\n",
        "      h_list.append(h)\n",
        "\n",
        "    ll = torch.stack(h_list, dim=1)\n",
        "    return self.o2o(self.att(ll))\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = ManillaRNN(vocab_size, embedding_dim, hidden_size, 3)\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "2oAWXfu7d2fc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iters = 10000\n",
        "for i in range(n_iters):\n",
        "  inputs, targets = get_batch()\n",
        "  predicts = model(inputs, targets)\n",
        "  loss = criterion(predicts, targets)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if i % 1000 == 0:\n",
        "    print(f'i {i}, loss:{loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Np5sy8Wd7H9",
        "outputId": "0b6f383b-07a3-4e13-a910-70ae03e45f7c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i 0, loss:0.14427700638771057\n",
            "i 1000, loss:0.22208979725837708\n",
            "i 2000, loss:0.03930990397930145\n",
            "i 3000, loss:0.06305910646915436\n",
            "i 4000, loss:0.000996256247162819\n",
            "i 5000, loss:0.04364485293626785\n",
            "i 6000, loss:0.04226581007242203\n",
            "i 7000, loss:0.003924104850739241\n",
            "i 8000, loss:0.10018892586231232\n",
            "i 9000, loss:0.22880451381206512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hhh = \"a waste of time\"\n",
        "hgg = torch.tensor([word_to_index[word] for word in hhh.split(' ')])\n",
        "hgg = hgg.unsqueeze(0)\n",
        "pred = model(hgg, None)\n",
        "print(index_to_sentiment[torch.argmax(pred).item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sickUWxq0AZI",
        "outputId": "2791300e-f93d-4c86-a44b-a815c3c3afb0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n"
          ]
        }
      ]
    }
  ]
}