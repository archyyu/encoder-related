{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMxrt48RxQ1bzjcAAWW/iy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archyyu/encoder-related/blob/main/encoder_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFaVGmvM2FOC"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/archyyu/publicResource/main/chat_dataset.csv')"
      ],
      "metadata": {
        "id": "9fz7e2OpQvQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "hidden_size = 100\n",
        "embedding_dim = 40\n",
        "seq_length = 25\n",
        "learning_rate = 1e-1\n",
        "batch_size = 20\n",
        "dropout = 0.1\n",
        "eval_iters = 200\n",
        "num_heads = 8\n",
        "head_size = 16"
      ],
      "metadata": {
        "id": "7_VDGwea6Ktm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad = '<pad>'\n",
        "data = []\n",
        "targets = []\n",
        "for index, row in df.iterrows():\n",
        "  data.append(row['message'])\n",
        "  targets.append(row['sentiment'])"
      ],
      "metadata": {
        "id": "4INzfntYQ5IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targetset = sorted(set(targets))\n",
        "sentiment_to_index = {s:i for i, s in enumerate(targetset)}\n",
        "index_to_sentiment = {i:s for i, s in enumerate(targetset)}"
      ],
      "metadata": {
        "id": "_AZ900ZBSPyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sorted(set((' '.join(data)).split(' ')))\n",
        "dataset.append(pad)\n",
        "vocab_size = len(dataset)\n",
        "word_to_index = {w:i for i, w in enumerate(dataset)}\n",
        "index_to_word = {i:w for i, w in enumerate(dataset)}"
      ],
      "metadata": {
        "id": "fYvtMMv0SXvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = []\n",
        "for item in data:\n",
        "  lines.append(item.split(' '))\n",
        "\n",
        "max_line = max([len(line) for line in lines])"
      ],
      "metadata": {
        "id": "5AVifPEUX7Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in lines:\n",
        "  for _ in range(max_line - len(item)):\n",
        "    item.append(pad)"
      ],
      "metadata": {
        "id": "nvcrv9J3Yfpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "for line in lines:\n",
        "  item = [word_to_index[word] for word in line]\n",
        "  X.append(item)\n",
        "\n",
        "Y = []\n",
        "for i in range(len(targets)):\n",
        "  item = sentiment_to_index[targets[i]]\n",
        "  Y.append(item)"
      ],
      "metadata": {
        "id": "bYBoiEbOTy83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self, embedding_size, head_size):\n",
        "    super(AttentionHead, self).__init__()\n",
        "    self.head_size = head_size\n",
        "    self.C = embedding_size\n",
        "\n",
        "    self.q = nn.Linear(self.C, head_size, bias=False)\n",
        "    self.v = nn.Linear(self.C, head_size, bias=False)\n",
        "    self.k = nn.Linear(self.C, head_size, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B,T,C = x.shape\n",
        "    q = self.q(x)\n",
        "    k = self.k(x)\n",
        "    v = self.v(x)\n",
        "\n",
        "    wei = q @ k.transpose(-2, -1) * (self.head_size ** -0.5)\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "    return wei @ v\n",
        "\n",
        "class EncoderMultiHeadAttention(nn.Module):\n",
        "  def __init__(self, num_heads, embedding_size, head_size):\n",
        "    super(EncoderMultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.heads = nn.ModuleList([\n",
        "        AttentionHead(embedding_size, head_size) for _ in range(num_heads)\n",
        "    ])\n",
        "\n",
        "    self.final_linear = nn.Linear(num_heads * head_size, embedding_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    head_outputs = [head(x) for head in self.heads]\n",
        "    concatenated_output = torch.cat(head_outputs, dim=-1)\n",
        "    final_output = self.final_linear(concatenated_output)\n",
        "    return self.dropout(final_output)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, embedding_size):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(embedding_size, 4 * embedding_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4 * embedding_size, embedding_size),\n",
        "        nn.Dropout(dropout),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "class EncoderBlockAttention(nn.Module):\n",
        "  def __init__(self, num_heads, embedding_size, head_size):\n",
        "    super(EncoderBlockAttention, self).__init__()\n",
        "    self.multiheads = EncoderMultiHeadAttention(num_heads, embedding_size, head_size)\n",
        "    self.fw = FeedForward(embedding_size)\n",
        "    self.norm1 = nn.LayerNorm(embedding_size)\n",
        "    self.norm2 = nn.LayerNorm(embedding_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    inter_result = x + self.multiheads(self.norm1(x))\n",
        "    final_result = x + self.fw(self.norm2(inter_result))\n",
        "    return final_result\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, num_heads, vocab_size, embedding_size, output_size, head_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.em = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.pos_encode = nn.Embedding(seq_length, embedding_size)\n",
        "    self.blocks = nn.ModuleList([EncoderBlockAttention(num_heads, embedding_size, head_size) for _ in range(4)])\n",
        "    self.f_norm = nn.LayerNorm(embedding_size)\n",
        "    self.fw = nn.Linear(embedding_size, output_size, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B,T = x.shape\n",
        "    x_em = self.em(x)\n",
        "    p_em = self.pos_encode(torch.arange(T))\n",
        "\n",
        "    x = x_em + p_em\n",
        "    for block in self.blocks:\n",
        "      x = block(x)\n",
        "    x = self.f_norm(x)\n",
        "    x = self.fw(x)\n",
        "    return torch.clone(x[:,T-1,:]).squeeze(1)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = Encoder(num_heads, vocab_size, embedding_dim, 3, head_size)\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "SIGRVqLNVdgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch():\n",
        "  inputs = []\n",
        "  targets = []\n",
        "  n = torch.randint(len(X) - batch_size, [1]).item()\n",
        "  for i in range(batch_size):\n",
        "    inputs_item = torch.tensor(X[n + i])\n",
        "    targets_item = torch.tensor(Y[n + i])\n",
        "    inputs.append(inputs_item)\n",
        "    targets.append(targets_item)\n",
        "\n",
        "  return torch.stack(inputs), torch.stack(targets)"
      ],
      "metadata": {
        "id": "h5OFKwKM6ElH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "on1 = torch.rand((3,4,5))\n",
        "print(on1)\n",
        "print(torch.clone(on1[:,3,:]).squeeze(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1wKxwtA8k0C",
        "outputId": "a5ed77bb-3fb8-4c27-95a3-0172458d36ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.9479, 0.7091, 0.4131, 0.5498, 0.6462],\n",
            "         [0.5467, 0.6809, 0.9910, 0.0813, 0.1717],\n",
            "         [0.9783, 0.5267, 0.0978, 0.5695, 0.2302],\n",
            "         [0.1460, 0.0410, 0.2111, 0.1425, 0.5241]],\n",
            "\n",
            "        [[0.7104, 0.3916, 0.1105, 0.1457, 0.2464],\n",
            "         [0.9301, 0.1063, 0.4606, 0.4025, 0.9448],\n",
            "         [0.8151, 0.7580, 0.3681, 0.9758, 0.9931],\n",
            "         [0.4659, 0.4371, 0.2802, 0.8284, 0.9607]],\n",
            "\n",
            "        [[0.6110, 0.1068, 0.4580, 0.5537, 0.4714],\n",
            "         [0.9458, 0.9476, 0.4988, 0.6737, 0.2731],\n",
            "         [0.8914, 0.7820, 0.9837, 0.1294, 0.9168],\n",
            "         [0.2468, 0.5949, 0.7835, 0.4914, 0.5822]]])\n",
            "tensor([[0.1460, 0.0410, 0.2111, 0.1425, 0.5241],\n",
            "        [0.4659, 0.4371, 0.2802, 0.8284, 0.9607],\n",
            "        [0.2468, 0.5949, 0.7835, 0.4914, 0.5822]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_iters = 1000\n",
        "for i in range(n_iters):\n",
        "  inputs, targets = get_batch()\n",
        "\n",
        "  predicts = model(inputs)\n",
        "\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  B,T = predicts.shape\n",
        "\n",
        "  loss = criterion(predicts, targets)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  if i%500 == 0:\n",
        "    print(f'i {i}, loss:{loss.item()}')"
      ],
      "metadata": {
        "id": "jamQ4eJv7Vdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hhh = \"I have no feeling with this\"\n",
        "\n",
        "hgg = [word_to_index[word] for word in hhh.split(' ')]\n",
        "for i in range(max_line - len(hgg)):\n",
        "  hgg.append(word_to_index[pad])\n",
        "\n",
        "# hgg = torch.stack(hgg)\n",
        "\n",
        "hgg = torch.tensor(hgg).unsqueeze(0)\n",
        "\n",
        "pred = model(hgg)\n",
        "print(index_to_sentiment[torch.argmax(pred).item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBo-hU1c7ZnD",
        "outputId": "6dc8d693-a75d-4743-801e-f2cbc9182304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral\n"
          ]
        }
      ]
    }
  ]
}