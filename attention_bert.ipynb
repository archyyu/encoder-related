{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt+vebV73i6G7f2pEhLO7/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archyyu/encoder-related/blob/main/attention_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nFaVGmvM2FOC"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/archyyu/publicResource/main/chat_dataset.csv')"
      ],
      "metadata": {
        "id": "9fz7e2OpQvQt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "hidden_size = 100\n",
        "embedding_dim = 80\n",
        "seq_length = 25\n",
        "learning_rate = 1e-1\n",
        "batch_size = 20\n",
        "dropout = 0.1\n",
        "eval_iters = 200\n",
        "num_heads = 4\n",
        "head_size = 20"
      ],
      "metadata": {
        "id": "7_VDGwea6Ktm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad = '[pad]'\n",
        "mask = '[MASK]'\n",
        "data = []\n",
        "targets = []\n",
        "for index, row in df.iterrows():\n",
        "  data.append(row['message'])\n",
        "  targets.append(row['sentiment'])\n",
        "\n",
        "datalen = []\n",
        "for line in data:\n",
        "  datalen.append(len(line.split(' ')))\n",
        "\n",
        "\n",
        "targetset = sorted(set(targets))\n",
        "sentiment_to_index = {s:i for i, s in enumerate(targetset)}\n",
        "index_to_sentiment = {i:s for i, s in enumerate(targetset)}"
      ],
      "metadata": {
        "id": "4INzfntYQ5IE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sorted(set((' '.join(data)).split(' ')))\n",
        "dataset.append(pad)\n",
        "dataset.append(mask)\n",
        "vocab_size = len(dataset)\n",
        "word_to_index = {w:i for i, w in enumerate(dataset)}\n",
        "index_to_word = {i:w for i, w in enumerate(dataset)}\n",
        "\n",
        "pad_index = word_to_index[pad]\n",
        "\n",
        "n = (int)(len(data) * 0.9)\n",
        "training_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "fYvtMMv0SXvp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = []\n",
        "for item in data:\n",
        "  lines.append(item.split(' '))\n",
        "\n",
        "max_line = max([len(line) for line in lines])\n",
        "\n",
        "for item in lines:\n",
        "  for _ in range(max_line - len(item)):\n",
        "    item.append(pad)\n",
        "\n",
        "X = []\n",
        "for line in lines:\n",
        "  item = [word_to_index[word] for word in line]\n",
        "  X.append(item)\n",
        "\n",
        "Y = []\n",
        "for i in range(len(targets)):\n",
        "  item = sentiment_to_index[targets[i]]\n",
        "  Y.append(item)"
      ],
      "metadata": {
        "id": "nvcrv9J3Yfpt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self, embedding_size, head_size):\n",
        "    super(AttentionHead, self).__init__()\n",
        "    self.head_size = head_size\n",
        "    self.C = embedding_size\n",
        "\n",
        "    self.q = nn.Linear(self.C, head_size, bias=False)\n",
        "    self.v = nn.Linear(self.C, head_size, bias=False)\n",
        "    self.k = nn.Linear(self.C, head_size, bias=False)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    B,T,C = x.shape\n",
        "    q = self.q(x)\n",
        "    k = self.k(x)\n",
        "    v = self.v(x)\n",
        "\n",
        "    wei = q @ k.transpose(-2, -1) * (self.head_size ** -0.5)\n",
        "    wei.masked_fill_(mask==0, -1e9)\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "    return wei @ v\n",
        "\n",
        "class EncoderMultiHeadAttention(nn.Module):\n",
        "  def __init__(self, num_heads, embedding_size, head_size):\n",
        "    super(EncoderMultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.heads = nn.ModuleList([\n",
        "        AttentionHead(embedding_size, head_size) for _ in range(num_heads)\n",
        "    ])\n",
        "\n",
        "    self.final_linear = nn.Linear(num_heads * head_size, embedding_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    head_outputs = [head(x, mask) for head in self.heads]\n",
        "    concatenated_output = torch.cat(head_outputs, dim=-1)\n",
        "    final_output = self.final_linear(concatenated_output)\n",
        "    return self.dropout(final_output)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, embedding_size):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(embedding_size, 4 * embedding_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4 * embedding_size, embedding_size),\n",
        "        nn.Dropout(dropout),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "class AddAndNormLayer(nn.Module):\n",
        "  def __init__(self, embedding_size):\n",
        "    super(AddAndNormLayer, self).__init__()\n",
        "    self.norm = nn.LayerNorm(embedding_size)\n",
        "\n",
        "  def forward(self, x, subLayer: nn.Module, mask=None):\n",
        "    if mask == None:\n",
        "      return x + subLayer(self.norm(x))\n",
        "    else:\n",
        "      return x + subLayer(self.norm(x), mask)\n",
        "\n",
        "class EncoderBlockAttention(nn.Module):\n",
        "  def __init__(self, num_heads, embedding_size, head_size):\n",
        "    super(EncoderBlockAttention, self).__init__()\n",
        "    self.multiheads = EncoderMultiHeadAttention(num_heads, embedding_size, head_size)\n",
        "    self.fw = FeedForward(embedding_size)\n",
        "    self.addLayers = nn.ModuleList([AddAndNormLayer(embedding_size) for i in range(2)])\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    inter_result = self.addLayers[0](x, self.multiheads, mask)\n",
        "    final_result = self.addLayers[1](inter_result, self.fw)\n",
        "    return final_result\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d_model, seq_len):\n",
        "    super().__init__()\n",
        "    self.C = d_model\n",
        "    T = seq_len\n",
        "    n = 10000\n",
        "    pe = torch.zeros((T, self.C))\n",
        "    for k in range(T):\n",
        "      for i in torch.arange(int(self.C/2)):\n",
        "        denominator = torch.pow(n, 2*i/self.C)\n",
        "        pe[k, 2*i] += torch.sin(k/denominator)\n",
        "        pe[k, 2*i+1] += torch.cos(k/denominator)\n",
        "\n",
        "    pe.requires_grad_(False)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x + self.pe\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, num_heads, vocab_size, embedding_size, head_size, seq_len):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.em = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.pe = PositionalEncoding(embedding_size, seq_len)\n",
        "    self.embedding_size = embedding_size\n",
        "    self.blocks = nn.ModuleList([EncoderBlockAttention(num_heads, embedding_size, head_size) for _ in range(4)])\n",
        "    self.f_norm = nn.LayerNorm(embedding_size)\n",
        "    self.fw = nn.Linear(embedding_size, vocab_size, bias=False)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    B,T = x.shape\n",
        "    x_em = self.em(x)\n",
        "    x = self.pe(x_em)\n",
        "    for block in self.blocks:\n",
        "      x = block(x, mask)\n",
        "    x = self.f_norm(x)\n",
        "    x = self.fw(x)\n",
        "    return x\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = Encoder(num_heads, vocab_size, embedding_dim, head_size, max_line)\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "SIGRVqLNVdgF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch():\n",
        "  inputs = []\n",
        "  targets = []\n",
        "  mask_index_list = []\n",
        "  masks = []\n",
        "  n = torch.randint(len(X) - batch_size, [1]).item()\n",
        "  for i in range(batch_size):\n",
        "    inputs_item = torch.tensor(X[n + i])\n",
        "\n",
        "    mask_index = torch.randint(datalen[n + 1], [1])\n",
        "\n",
        "    targets.append(inputs_item[mask_index])\n",
        "    mask_index_list.append(torch.tensor([i,mask_index]))\n",
        "\n",
        "    inputs_item[mask_index] = word_to_index[mask]\n",
        "\n",
        "    inputs.append(inputs_item)\n",
        "\n",
        "    masks.append(inputs_item != pad_index)\n",
        "\n",
        "  return torch.stack(inputs), torch.stack(targets), torch.stack(mask_index_list), torch.stack(masks).unsqueeze(1)"
      ],
      "metadata": {
        "id": "h5OFKwKM6ElH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iters = 10000\n",
        "for i in range(n_iters):\n",
        "  inputs, targets, indices, masks = get_batch()\n",
        "\n",
        "  predicts = model(inputs, masks)\n",
        "\n",
        "  #print(targets.view(-1).shape)\n",
        "  outputs = predicts[indices[:,0],indices[:,1]]\n",
        "  #print(outputs.shape)\n",
        "\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "  loss = criterion(outputs, targets.view(-1))\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  if i%500 == 0:\n",
        "    print(f'i {i}, loss:{loss.item()}')"
      ],
      "metadata": {
        "id": "jamQ4eJv7Vdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef73b812-1e5a-4cc8-97a7-9d8f4f2910b4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i 0, loss:0.9897297024726868\n",
            "i 500, loss:0.5745040774345398\n",
            "i 1000, loss:0.5397576689720154\n",
            "i 1500, loss:0.6856590509414673\n",
            "i 2000, loss:0.5614961385726929\n",
            "i 2500, loss:0.5877989530563354\n",
            "i 3000, loss:0.349053293466568\n",
            "i 3500, loss:0.8374935388565063\n",
            "i 4000, loss:1.155908226966858\n",
            "i 4500, loss:0.08496621251106262\n",
            "i 5000, loss:0.43738698959350586\n",
            "i 5500, loss:1.1929086446762085\n",
            "i 6000, loss:0.7024846076965332\n",
            "i 6500, loss:0.46525293588638306\n",
            "i 7000, loss:0.8066798448562622\n",
            "i 7500, loss:0.7971165776252747\n",
            "i 8000, loss:0.7153050899505615\n",
            "i 8500, loss:0.6752622723579407\n",
            "i 9000, loss:0.701088547706604\n",
            "i 9500, loss:1.0237014293670654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = torch.randint(len(X) - 20,[1]).item()\n",
        "for line in data[-n:-n + 15]:\n",
        "  hgg = [word_to_index[word] for word in line.split(' ')]\n",
        "  linelen = len(hgg)\n",
        "  for i in range(max_line - len(hgg)):\n",
        "    hgg.append(word_to_index[pad])\n",
        "  maskindex = torch.randint(linelen,[1]).item()\n",
        "  hgg[maskindex] = word_to_index['[MASK]']\n",
        "  print(' '.join([index_to_word[item] for item in hgg]))\n",
        "  hgg = torch.tensor(hgg).unsqueeze(0)\n",
        "  mask = (hgg != pad_index)\n",
        "  predict = model(hgg, mask)\n",
        "  values, indexes = torch.topk(predict[0][maskindex],3)\n",
        "  for item in indexes:\n",
        "    print('  ',index_to_word[item.item()])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLgsz4giQUvp",
        "outputId": "bbba9002-b73a-420f-a70a-f94cb7a09829"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm feeling a bit stuck right [MASK] üö∂‚Äç‚ôÄÔ∏è [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   now\n",
            "   today\n",
            "   [pad]\n",
            "I'm not [MASK] what to do with my free time ü§∑‚Äç‚ôÇÔ∏è [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   sure\n",
            "   what\n",
            "   happy\n",
            "I'm just trying to figure things out [MASK] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   my\n",
            "   in\n",
            "   üîç\n",
            "I'm feeling a bit overwhelmed with [MASK] going on üò© [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   out\n",
            "   my\n",
            "   everything\n",
            "I'm not sure if I'm [MASK] the right decision ü§î [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   making\n",
            "   ready\n",
            "   for\n",
            "I'm just [MASK] things one step at a time üö∂‚Äç‚ôÇÔ∏è [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   taking\n",
            "   on\n",
            "   impressed\n",
            "I'm feeling a bit frustrated [MASK] üò§ [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   today\n",
            "   üòê\n",
            "   now\n",
            "I'm not sure if I should say [MASK] ü§´ [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   anything\n",
            "   ü§î\n",
            "   out\n",
            "I'm [MASK] trying to keep things in perspective üåÖ [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   just\n",
            "   so\n",
            "   trying\n",
            "[MASK] feeling a bit confused right now ü§∑‚Äç‚ôÄÔ∏è [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   I'm\n",
            "   I\n",
            "   My\n",
            "I'm not sure what to do [MASK] ü§∑‚Äç‚ôÇÔ∏è [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   my\n",
            "   this\n",
            "   with\n",
            "I'm just trying [MASK] stay focused on my goals üéØ [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   to\n",
            "   with\n",
            "   on\n",
            "I'm feeling a bit lost [MASK] my phone üì± [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   the\n",
            "   without\n",
            "   everything\n",
            "I'm not sure if I [MASK] go out tonight ü§î [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   should\n",
            "   want\n",
            "   reach\n",
            "I'm just trying [MASK] find my way üó∫Ô∏è [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad] [pad]\n",
            "   out\n",
            "   to\n",
            "   time\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "that is amazing\n",
        "I masked one word in the sentence, then training to model to predict the masked word\n",
        "\n",
        "after some epoches, it works. even though, it maynot predicts the exact word, but it will predict very similar word\n",
        "\n",
        "will continue"
      ],
      "metadata": {
        "id": "y_9ByyHrMDU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the same with encoder_sentiment\n",
        "updated with three things\n",
        "1: use a class to encapsulate the add and norm layer\n",
        "2: mask the pad tokens, so the pad tokens did not get attention\n",
        "3: add position encoding\n",
        "\n",
        "overall, the performance is better now."
      ],
      "metadata": {
        "id": "HZny9M16W43Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using the transformer encoder as an bert\n",
        "then I will use dual-directional rnn to do a bert again\n",
        "to check which model will perform better"
      ],
      "metadata": {
        "id": "7U8Ex5Sd1QXC"
      }
    }
  ]
}